{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Clustering Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1. Newman Leading Eigenvector Clustering</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newman_leading_eigenvector( G ) :\n",
    "    A_not_sparse = []\n",
    "    for _ , nbrdict in G.adjacency():\n",
    "        A_not_sparse.append( list( nbrdict.keys() ) )\n",
    "\n",
    "    NODES = len(A_not_sparse)\n",
    "    A = np.zeros( ( NODES , NODES ) )\n",
    "\n",
    "    for i , adjacency_list in enumerate( A_not_sparse ):\n",
    "        for adj_node in adjacency_list :\n",
    "            A[ i ][ int(adj_node) ] = 1\n",
    "\n",
    "    D_vect = np.matmul( A , np.ones( ( A.shape[0] , 1 ) ) )\n",
    "#     B = mdoularity_matrix\n",
    "    B = A - np.matmul( D_vect , D_vect.T ) / np.sum( A )\n",
    "    eig_values , eig_vectors = np.linalg.eig( B )\n",
    "    copy_eigen_values = list(eig_values)\n",
    "    copy_eigen_values.sort( )\n",
    "    SL_eigen_value = copy_eigen_values[-1]\n",
    "    index_sl_largest_eigenvalue , = np.where( eig_values == SL_eigen_value )\n",
    "    eigen_vector = eig_vectors[ : , index_sl_largest_eigenvalue ]\n",
    "    eigen_vector.sort()\n",
    "#     plt.plot( range(NODES) , eigen_vector )\n",
    "#     plt.show(  )\n",
    "    comm1 , comm2 = show_community( eig_vectors[ : , index_sl_largest_eigenvalue ] ) \n",
    "    print( comm1 , comm2 )\n",
    "    return [ comm1 , comm2 ]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2. Newman Second Largest EigenVector Clustering</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newman_sl_eigenvector_community( G ):\n",
    "    A_not_sparse = []\n",
    "    for _ , nbrdict in G.adjacency():\n",
    "        A_not_sparse.append( list( nbrdict.keys() ) )\n",
    "\n",
    "    NODES = len(A_not_sparse)\n",
    "    A = np.zeros( ( NODES , NODES ) )\n",
    "\n",
    "    for i , adjacency_list in enumerate( A_not_sparse ):\n",
    "        for adj_node in adjacency_list :\n",
    "            A[ i ][ int(adj_node) ] = 1\n",
    "\n",
    "    D = np.power( np.matmul( A , np.ones( ( A.shape[0] , ) ) ) , -0.5 )\n",
    "    D_1_2 = np.diag( D )\n",
    "    L = np.matmul( np.matmul( D_1_2 , A ) , D_1_2)\n",
    "    \n",
    "    eig_values , eig_vectors = np.linalg.eig( L )\n",
    "    copy_eigen_values = list(eig_values)\n",
    "    copy_eigen_values.sort( )\n",
    "    SL_eigen_value = copy_eigen_values[-2]\n",
    "    index_sl_largest_eigenvalue , = np.where( eig_values == SL_eigen_value )\n",
    "    eigen_vector = eig_vectors[ : , index_sl_largest_eigenvalue ]\n",
    "    eigen_vector.sort()\n",
    "#     plt.plot( range(NODES) , eigen_vector )\n",
    "#     plt.show(  )\n",
    "    print( show_community( eig_vectors[ : , index_sl_largest_eigenvalue ] ) )\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3. Fiedler Vector Clustering</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fiedler_vector_method( G ):\n",
    "    A_not_sparse = []\n",
    "    for _ , nbrdict in G.adjacency():\n",
    "        A_not_sparse.append( list( nbrdict.keys() ) )\n",
    "\n",
    "    NODES = len(A_not_sparse)\n",
    "    A = np.zeros( ( NODES , NODES ) )\n",
    "\n",
    "    for i , adjacency_list in enumerate( A_not_sparse ):\n",
    "        for adj_node in adjacency_list :\n",
    "            A[ i ][ int(adj_node) ] = 1\n",
    "    D = np.diag( np.matmul( A , np.ones( ( A.shape[0] ,  ) ) ) )\n",
    "    L = D - A\n",
    "    eig_values , eig_vectors = np.linalg.eig( L )\n",
    "    copy_eigen_values = list(eig_values)\n",
    "    copy_eigen_values.sort( )\n",
    "    SS_eigen_value = copy_eigen_values[1]\n",
    "    index_ss_eigenvalue , = np.where( eig_values == SS_eigen_value )\n",
    "    eigen_vector = eig_vectors[ : , index_ss_eigenvalue ]\n",
    "    eigen_vector.sort()\n",
    "#     plt.plot( range(NODES) , eigen_vector )\n",
    "#     plt.show(  )\n",
    "    comm1 , comm2 = show_community( eig_vectors[ : , index_ss_eigenvalue ] ) \n",
    "    print( comm1 , comm2 )\n",
    "    return [ comm1 , comm2 ]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Spectral Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1. Girvan-Newman</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def girvan_newman( G ):\n",
    "    communities_generator = community.girvan_newman(G)\n",
    "    top_level_communities = next(communities_generator)\n",
    "    next_level_communities = next(communities_generator)\n",
    "    return sorted(map(sorted, top_level_communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_community( eigenvector ):\n",
    "    comm1 = []\n",
    "    comm2 = []\n",
    "    for i , element in enumerate(eigenvector):\n",
    "        if element < 0:\n",
    "            comm1.append( i )\n",
    "        else:\n",
    "            comm2.append( i )\n",
    "    return comm1 , comm2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2. Label Propagation Method</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_propagation_method( G ):\n",
    "    communities_generator = community.label_propagation.asyn_lpa_communities(G)\n",
    "    comm_list = []\n",
    "    for comm in communities_generator:\n",
    "        comm = list(comm)\n",
    "        comm.sort()\n",
    "        comm_list.append(comm )\n",
    "    print(comm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_community_labels( comm1 , comm2 ):\n",
    "    labels = np.ones( len(comm1) + len(comm2) , )\n",
    "    for node in comm1:\n",
    "        labels[ node ] = 0\n",
    "    for node in comm2:\n",
    "        labels[ node ] = 1\n",
    "    return labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataSets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1. Zachary's Karate Club</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_zach = [ 0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,1,0,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1 ]\n",
    "len(ground_truth_zach)\n",
    "G = nx.karate_club_graph()\n",
    "G.degree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newman_leading_eigenvector(G) # 2 is incorrectly labelled\n",
    "newman_sl_eigenvector_community( G )\n",
    "girvan_newman( G )\n",
    "fiedler_vector_method( G )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2. Facebook</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES = 4039\n",
    "G = nx.read_edgelist(\"datasets/facebook_combined.txt.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# girvan_newman(G) #--DOES NOT WORK COMPUTSTIONALLY HARD\n",
    "newman_leading_eigenvector(G) \n",
    "newman_sl_eigenvector_community( G )\n",
    "fiedler_vector_method( G )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3. Dolphins Dataset</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES = 62\n",
    "G = nx.read_edgelist(\"datasets/dolphins.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the mapping of the nodes: make it 0 indexing\n",
    "mapping = {}\n",
    "for i in G.nodes:\n",
    "    mapping[str(i)] = int(i) - 1\n",
    "nx.relabel_nodes(G, mapping,copy=False)\n",
    "G.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newman_leading_eigenvector(G) # 2 is incorrectly labelled\n",
    "newman_sl_eigenvector_community( G )\n",
    "girvan_newman( G )\n",
    "fiedler_vector_method( G )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>4. Planted-Partition BenchmarkModel</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "number_of_groups = 2\n",
    "number_of_vertices = 500\n",
    "p_in = 0.85\n",
    "p_out = 0.15\n",
    "G_ppg = nx.planted_partition_graph( l = number_of_groups , k = number_of_vertices , p_in = p_in , p_out = p_out )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5. LFR Benchmark Graph</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "tau1 = 2\n",
    "tau2 = 3\n",
    "mu = 0.8\n",
    "# average_degree = 20\n",
    "min_degree = 25\n",
    "max_degree = 40\n",
    "min_community = 50\n",
    "G_LFR = nx.LFR_benchmark_graph( n = n , tau1 = tau1 , tau2 = tau2 , mu = mu\n",
    "                               , min_degree = min_degree , max_degree = max_degree ,\n",
    "                               min_community = min_community )\n",
    "# newman_leading_eigenvector( G_LFR )\n",
    "communities = {frozenset(G_LFR.nodes[v]['community']) for v in G_LFR}\n",
    "print(communities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Mutual Information(NMI) Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "# comm1 , comm2 = fiedler_vector_method( G )\n",
    "# labels = generate_community_labels( comm1 , comm2 )\n",
    "normalized_mutual_info_score( [0,1,2] , [2,1,0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comm1 , comm2 = fiedler_vector_method( G )\n",
    "labels = generate_community_labels( [0,1,2] , [2,1,0] )\n",
    "# normalized_mutual_info_score( ground_truth_zach , labels )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
